import akshare as ak  # æ›¿æ¢yfinanceï¼Œä¸“ä¸ºå›½å†…é‡‘èæ•°æ®è®¾è®¡
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import os
import time
import warnings
warnings.filterwarnings('ignore')

# ================== ç­–ç•¥é…ç½® ==================
ETF_MAP = {
    '510720': 'ä¸Šè¯çº¢åˆ©ETF',  # å›½å†…ETFä»£ç æ— éœ€åŠ .SSåç¼€
    '515180': 'ä¸­è¯çº¢åˆ©ETF', 
    '512890': 'çº¢åˆ©ä½æ³¢ETF'
}

DEFAULT_DIV = {
    '510720': 4.5,
    '515180': 4.2,
    '512890': 4.0
}

LOOKBACK_DAYS = 60      # åŠ¨é‡è§‚å¯ŸæœŸ
HOLDING_DAYS = 20       # æŒä»“å‘¨æœŸ
RISK_FREE_RATE = 0.02   # æ— é£é™©åˆ©ç‡
STOP_LOSS = -0.08       # æ­¢æŸçº¿
BATCH_SIZE = 3          # åˆ†æ‰¹å»ºä»“æ¬¡æ•°
DIV_CACHE_DAYS = 30     # è‚¡æ¯ç‡ç¼“å­˜å¤©æ•°
REQUEST_DELAY = 2       # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

# ================== è‚¡æ¯ç‡è·å–å‡½æ•° ==================
def get_dividend_rates():
    """é€šè¿‡ä¸œæ–¹è´¢å¯Œè·å–å›½å†…ETFè‚¡æ¯ç‡"""
    cache_file = 'dividend_cache.json'
    
    if os.path.exists(cache_file):
        with open(cache_file, 'r', encoding='utf-8') as f:
            try:
                cache = json.load(f)
                last_update = datetime.strptime(cache['last_update'], '%Y-%m-%d')
                if (datetime.now() - last_update).days < DIV_CACHE_DAYS:
                    print("ä½¿ç”¨ç¼“å­˜çš„è‚¡æ¯ç‡æ•°æ®")
                    return cache['rates']
            except:
                pass
    
    print("å¼€å§‹è·å–æœ€æ–°è‚¡æ¯ç‡...")
    div_rates = {}
    
    for ticker in ETF_MAP:
        try:
            # ä¸œæ–¹è´¢å¯ŒETFæ¦‚å†µæ¥å£ï¼ˆå›½å†…æ•°æ®æ›´å‡†ç¡®ï¼‰
            fund_profile = ak.fund_etf_profile_em(symbol=ticker)
            # æå–è‚¡æ¯ç‡ï¼ˆå¤„ç†ä¸­æ–‡æè¿°ï¼‰
            div_row = fund_profile[fund_profile['item'] == 'è‚¡æ¯ç‡']
            if not div_row.empty:
                div_value = div_row['value'].iloc[0]
                if '%' in div_value:
                    div_rate = float(div_value.strip('%'))
                    if 0 < div_rate < 15:
                        div_rates[ticker] = round(div_rate, 2)
                        print(f"  {ETF_MAP[ticker]} è‚¡æ¯ç‡: {div_rate}%")
                        continue
            
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆè‚¡æ¯ç‡")
                
        except Exception as e:
            print(f"  {ETF_MAP[ticker]} è‚¡æ¯ç‡è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {str(e)}")
            div_rates[ticker] = DEFAULT_DIV.get(ticker, 3.0)
        
        time.sleep(REQUEST_DELAY)
    
    # ä¿å­˜ç¼“å­˜
    cache_data = {
        'last_update': datetime.now().strftime('%Y-%m-%d'),
        'rates': div_rates
    }
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(cache_data, f, indent=2, ensure_ascii=False)
    
    return div_rates

# ================== æ•°æ®è·å– ==================
def fetch_etf_data():
    """è·å–å›½å†…ETFä»·æ ¼æ•°æ®ï¼ˆå…¼å®¹æœ€æ–°æ•°æ®æºæ ¼å¼ï¼‰"""
    etf_data = {}
    end_date = datetime.now().strftime('%Y%m%d')  # æ³¨æ„æ ¼å¼ä¿®æ”¹ä¸ºçº¯æ•°å­—
    start_date = (datetime.now() - timedelta(days=365*2)).strftime('%Y%m%d')  # 2å¹´æ•°æ®
    
    for ticker in ETF_MAP:
        try:
            print(f"è·å– {ETF_MAP[ticker]}({ticker}) ä»·æ ¼æ•°æ®...")
            # ä½¿ç”¨ä¸œæ–¹è´¢å¯ŒETFæ—¥çº¿æ¥å£ï¼ˆè°ƒæ•´å‚æ•°å’Œåˆ—åé€‚é…ï¼‰
            df = ak.fund_etf_hist_em(
                symbol=ticker,
                start_date=start_date,
                end_date=end_date,
                period="daily"
            )
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆæŸ¥çœ‹å®é™…è¿”å›çš„åˆ—åï¼‰
            print(f"  æ•°æ®æºè¿”å›åˆ—å: {df.columns.tolist()}")
            
            # çµæ´»åŒ¹é…åˆ—åï¼ˆå¤„ç†å¯èƒ½çš„åˆ—åå˜åŒ–ï¼‰
            date_cols = [col for col in df.columns if 'æ—¥æœŸ' in col]
            close_cols = [col for col in df.columns if 'æ”¶ç›˜' in col]
            
            if not date_cols or not close_cols:
                raise ValueError("æœªæ‰¾åˆ°æ—¥æœŸæˆ–æ”¶ç›˜ä»·åˆ—")
            
            # é‡å‘½åä¸ºæ ‡å‡†åŒ–åˆ—å
            df = df.rename(columns={
                date_cols[0]: 'date',
                close_cols[0]: 'close',
            })
            
            # ç¡®ä¿åŒ…å«å¿…è¦çš„ä»·æ ¼åˆ—
            required_cols = ['date', 'close']
            if not all(col in df.columns for col in required_cols):
                raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {required_cols}")
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼å¹¶æ’åº
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').set_index('date')
            
            # æ£€æŸ¥æ•°æ®é‡
            if len(df) < LOOKBACK_DAYS:
                raise ValueError(f"æ•°æ®ä¸è¶³{LOOKBACK_DAYS}æ¡ï¼ˆä»…è·å–{len(df)}æ¡ï¼‰")
            
            etf_data[ticker] = df
            print(f"  æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
            
        except Exception as e:
            print(f"  {ETF_MAP[ticker]} ä»·æ ¼æ•°æ®è·å–å¤±è´¥: {str(e)}")
        
        time.sleep(2)  # å»¶é•¿è¯·æ±‚é—´éš”ï¼Œé¿å…è¢«é™åˆ¶
    
    return etf_data

# ================== æŒ‡æ ‡è®¡ç®— ==================
def calculate_signals(data_dict, div_rates):
    """è®¡ç®—äº¤æ˜“ä¿¡å·"""
    signals = pd.DataFrame()
    
    for ticker, df in data_dict.items():
        if len(df) < LOOKBACK_DAYS:
            continue
            
        returns = np.log(df['close'] / df['close'].shift(1))
        momentum = df['close'].pct_change(periods=LOOKBACK_DAYS)
        volatility = returns.rolling(LOOKBACK_DAYS).std() * np.sqrt(252)
        
        # å¤„ç†æ³¢åŠ¨ç‡ä¸º0çš„ç‰¹æ®Šæƒ…å†µ
        if volatility.iloc[-1] == 0:
            sharpe = momentum.iloc[-1] * 10  # ç®€å•æ›¿ä»£
        else:
            sharpe = (momentum - RISK_FREE_RATE/252) / volatility
        
        div_factor = div_rates.get(ticker, 3.0) / 100
        score = sharpe * 0.7 + div_factor * 0.3
        
        signals[ticker] = score
    
    signals.dropna(inplace=True)
    return signals

# ================== ä¸»å‡½æ•° ==================
if __name__ == "__main__":
    print("çº¢åˆ©ETFè½®åŠ¨ç­–ç•¥ (å›½å†…æ•°æ®æºç‰ˆ)")
    
    # 1. è·å–è‚¡æ¯ç‡æ•°æ®
    div_rates = get_dividend_rates()
    
    # 2. è·å–ä»·æ ¼æ•°æ®
    print("\nè·å–ETFä»·æ ¼æ•°æ®...")
    etf_data = fetch_etf_data()
    
    if not etf_data:
        print("ä»·æ ¼æ•°æ®è·å–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
    else:
        # 3. è®¡ç®—ä¿¡å·
        signals = calculate_signals(etf_data, div_rates)
        
        if not signals.empty:
            print("\næœ€æ–°ä¿¡å·ï¼ˆåˆ†æ•°è¶Šé«˜è¶Šä¼˜ï¼‰:")
            print(signals.tail(1).T.sort_values(by=signals.index[-1], ascending=False))
            
            # è¾“å‡ºæ¨èæ ‡çš„
            best_ticker = signals.iloc[-1].idxmax()
            print(f"\nå½“å‰æ¨èæ ‡çš„: {ETF_MAP[best_ticker]}({best_ticker})")
        else:
            print("æ— æ³•ç”Ÿæˆæœ‰æ•ˆä¿¡å·")
            import requests

def send_wechat_notification(message):
    """é€šè¿‡ Serveré…± å‘é€å¾®ä¿¡é€šçŸ¥"""
    sendkey = "ä½ çš„_Serveré…±_SendKey"  # æ›¿æ¢æˆä½ çš„ SendKeyï¼ˆåé¢ä¼šè®²å¦‚ä½•è·å–ï¼‰
    url = f"https://sctapi.ftqq.com/{sendkey}.send"
    data = {
        "text": "çº¢åˆ©ä¸‰å‰‘å®¢",  # å¾®ä¿¡æ¶ˆæ¯æ ‡é¢˜
        "desp": message           # å¾®ä¿¡æ¶ˆæ¯å†…å®¹ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰
    }
    try:
        response = requests.post(url, data=data)
        print("å¾®ä¿¡é€šçŸ¥å‘é€æˆåŠŸ:", response.text)
    except Exception as e:
        print("å¾®ä¿¡é€šçŸ¥å‘é€å¤±è´¥:", str(e))

# åœ¨é€‰è‚¡å®Œæˆåè°ƒç”¨ï¼ˆç¤ºä¾‹ï¼‰
if 'selected_etf' in locals() and 'last_signal' in locals():
    selected_name = ETF_CONFIG[selected_etf]['name']
    message = f"""
    ğŸ“ˆ **ä»Šæ—¥ETFè½®åŠ¨ç»“æœ**
    - **æ¨èETF**: {selected_name} ({selected_etf})
    - **ä¿¡å·å¼ºåº¦**: {last_signal[selected_etf]:.4f}
    - **è‚¡æ¯ç‡**: {div_rates.get(selected_etf, 'N/A')}%
    - **è¿è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """
    send_wechat_notification(message)
else:
    send_wechat_notification("âŒ ç­–ç•¥è¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ï¼")